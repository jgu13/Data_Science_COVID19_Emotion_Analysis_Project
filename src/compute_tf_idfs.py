import argparse
import json
import os
import math


# to use:       ../data/label_words.json 10


def tf(w, label):
    return label[w]


def idf(w, counts):
    num_labels = len(counts)
    w_sayers = 0  # number of users who say w
    for label in counts:
        if w in counts[label]:
            w_sayers += 1
    return math.log(num_labels/w_sayers)


def tf_idf(w, label, counts):
    return tf(w, label) * idf(w, counts)


def main(count_file, num_words):
    with open(count_file, 'r') as f:
        counts = json.load(f)

    tf_idf_values = {}

    for label in counts:
        tf_idf_values[label] = []
        scores = []
        for word in counts[label]:
            score = tf_idf(word, counts[label], counts)
            scores.append((score, word))
        best_scores = sorted(scores, reverse=True)
        for score in best_scores[0:num_words]:
            tf_idf_values[label].append(score[1])

    return tf_idf_values


if __name__ == '__main__':
    '''For use on the file generated by clean_data.py.
    (clean_data.py puts the output file in 'data/label_words.json')
    
    Ex: compute_tf_idfs.py data/label_words.json 10
    will find the top 10 words by tfidf for each label (economy, vaccine, etc.)
    '''

    parser = argparse.ArgumentParser()
    parser.add_argument('count_file')
    parser.add_argument('num_words')
    args = parser.parse_args()
    count_file = args.count_file
    num_words = int(args.num_words)

    output = main(count_file, num_words)
    print(json.dumps(output, indent=4))

    script_path = os.path.abspath(os.path.dirname(__file__))
    with open(os.path.join(script_path, '..', 'data', 'tf_idfs.json'), 'w') as f:
        json.dump(output, f, indent=4)
